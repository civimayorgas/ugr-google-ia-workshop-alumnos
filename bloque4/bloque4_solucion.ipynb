{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4420b92-0cc8-4c3b-a414-09fc840fb911",
   "metadata": {},
   "source": [
    "# Bloque 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e367bd-f1ae-4cd0-b38e-6a493592ad1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform_v1\n",
    "import streamlit as st \n",
    "from google.cloud import bigquery\n",
    "from langchain_google_vertexai.llms import VertexAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import vertexai\n",
    "import os\n",
    "from langchain_google_vertexai import VertexAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cabcf3c-e34d-4813-8d02-4eeb80cf4f08",
   "metadata": {},
   "source": [
    "# Definir una función bot_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e449e3-93b7-42e2-813b-ff1c79257321",
   "metadata": {},
   "source": [
    "### Esta función debe encapsular:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e75b8-517a-4f3d-a71b-8b9aac044412",
   "metadata": {},
   "source": [
    "- Obtenención de la descripción del producto y su embedding\n",
    "- Obtención producto más similar y recomendarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1369b6f8-b8cd-492b-89c9-e29ac4a6dbf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuración para el índice desplegado\n",
    "API_ENDPOINT=\"2069128544.us-central1-1043238928011.vdb.vertexai.goog\"\n",
    "INDEX_ENDPOINT=\"projects/1043238928011/locations/us-central1/indexEndpoints/6459098649556156416\"\n",
    "DEPLOYED_INDEX_ID=\"products_data_index_civica\"\n",
    "\n",
    "# Cliente Vector Search\n",
    "client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "vector_search_client = aiplatform_v1.MatchServiceClient(client_options=client_options)\n",
    "\n",
    "# Cliente BigQuery\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Obtención embeddings\n",
    "embeddings = VertexAIEmbeddings(model_name=\"textembedding-gecko@001\")   ### Utilizamos la clase VertexAIEmbeddings y el método embed_query()\n",
    "\n",
    "# Configuración LLM (Gemini)\n",
    "llm = VertexAI(model_name=\"gemini-pro\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa72c00-3342-4eea-add2-3d778b665b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_template = \"\"\"Eres el primer eslabón de una cadena que conformará un bot ecommerce y necesito en este primer paso recoger únicamente la información referente al producto que nos da el usuario.\n",
    "\n",
    "El objetivo es que a partir de tu output se generará un embedding para buscar este producto que pide el usuario en nuestra base de datos vectorial (por tanto no te inventes nada).\n",
    "\n",
    "Ejemplo: \"Quiero unas gafas de sol negras porque estamos en verano\", tu output debe ser \"Gafas de sol negras\".\n",
    "\n",
    "La pregunta introducida por el usuario es: \"{question}\"\n",
    "\n",
    "Output para generar el embedding: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5723783b-9fc1-4ceb-9302-bcbe0c701c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_embedding_template = PromptTemplate.from_template(embedding_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c134caef-240d-4538-b789-da9a8c0b3c38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_chain = prompt_embedding_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b569b573-cfcf-4d85-ac80-63414acda0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Eres un bot encargado de responder y asesorar sobre productos de\n",
    "una tienda en linea (ecommerce). Por lo tanto, se respetuoso y trata cordialmente a las personas.\n",
    "Si la pregunta suya no tiene nada que ver con asesoramiento de productos, dile que ese no es tu trabajo.\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "El resultado más similar encontrado en la base de datos de productos es el siguiente:\n",
    "{most_similar}\n",
    "\n",
    "Dile al cliente nuestra recomendación según lo que ha preguntado informándole de todo lo posible para que pueda decidirse en su compra como nombre del artículo o precio.\n",
    "Responde en el mismo idioma en el que te pregunten.\n",
    "\n",
    "Respuesta: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d24389-895b-48f7-a76d-40fbf6e9eeba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6fc684-ccb9-4eda-adff-b7b56eb81ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Hola, qué tal, quiero unos vaqueros azules de talla pequeña porque tengo una fiesta mañana\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "327800c6-5b91-4611-8139-2f7a8212e478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e918b29-963b-4aa1-81b0-242d7d62209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot_answer(prompt):\n",
    "\n",
    "    # Ejecutamos la cadena chain_embedding para obtener la descripción del producto en el que está interesado el usuario utilizando Gemini\n",
    "    prompt_embedding = embedding_chain.invoke({\"question\": prompt})\n",
    "    print(f\"Texto para embedding: {prompt_embedding}\")\n",
    "    \n",
    "    # Construcción FindNeighborsRequest object\n",
    "    datapoint = aiplatform_v1.IndexDatapoint(\n",
    "      feature_vector=embeddings.embed_query(prompt_embedding)\n",
    "    )\n",
    "    query = aiplatform_v1.FindNeighborsRequest.Query(\n",
    "      datapoint=datapoint,     \n",
    "      neighbor_count=3  # Número de vecinos cercanos a recuperar\n",
    "    )\n",
    "    request = aiplatform_v1.FindNeighborsRequest(\n",
    "      index_endpoint=INDEX_ENDPOINT,\n",
    "      deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "      queries=[query],\n",
    "      return_full_datapoint=False,\n",
    "    )\n",
    "\n",
    "    # Ejecutamos request y obtenemos el id en BBDD del producto más similar a la descripción pedida por el usuario\n",
    "    response = vector_search_client.find_neighbors(request)\n",
    "    neighbors = response.nearest_neighbors[0].neighbors \n",
    "    most_similar = neighbors[0].datapoint.datapoint_id\n",
    "    \n",
    "    # Buscamos el ID en BigQuery para obtener el resto de información\n",
    "    sql = f\"\"\"\n",
    "    SELECT category, brand, name, retail_price as price, department as gender\n",
    "    FROM ia-ugr.ecommerce.products\n",
    "    WHERE ID = {most_similar}\n",
    "    ;\n",
    "    \"\"\"\n",
    "    sql_result = client.query(sql).to_dataframe()\n",
    "    print(f\"Resultado SQL es: {sql_result}\")\n",
    "\n",
    "    # Ejecutamos la cadena chain para obtener la recomendación para el usuario utilizando la información recuparada de BigQuery y Gemini\n",
    "    bot_result = chain.invoke({\"question\": prompt, \"most_similar\": sql_result})\n",
    "\n",
    "    return bot_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39a6658a-0145-4532-aa30-b3df3005d88a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto para embedding: \"Vaqueros azules talla pequeña\" \n",
      "\n",
      "Resultado SQL es:   category   brand                                               name  price  \\\n",
      "0   Shorts  Hurley  Lowrider Juniors 2.5 Inch Shorts in Ice Blue b...   24.0   \n",
      "\n",
      "  gender  \n",
      "0  Women  \n"
     ]
    }
   ],
   "source": [
    "full_response = bot_answer(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f727d8-f57d-459b-98dc-3f836553dd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
